{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import \n",
    "import colamatch as clm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from brainmap.transformation import transformation\n",
    "%matplotlib notebook\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(name)s [%(levelname)s]:%(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filenames and read images and pointsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 1\n",
    "s2 = 2\n",
    "img_fname1 = \"../data/section_%s.tif\"%(str(s1).zfill(4))\n",
    "img_fname2 = \"../data/section_%s.tif\"%(str(s2).zfill(4)) \n",
    "points_fname1 = \"../data/section_%s.landmarks.txt\"%(str(s1).zfill(4))\n",
    "points_fname2 = \"../data/section_%s.landmarks.txt\"%(str(s2).zfill(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read landmarks and images\n",
    "pointlist1 = np.loadtxt(points_fname1).astype('int')\n",
    "pointlist2 = np.loadtxt(points_fname2).astype('int')\n",
    "print(len(pointlist1), len(pointlist2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform constellation matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "sampler1 = clm.RandomSampler(len(pointlist1), 4, num_samples)\n",
    "sampler2 = clm.RandomSampler(len(pointlist2), 4, num_samples)\n",
    "start = time.time()\n",
    "matches = clm.match(pointlist1, pointlist2, sampler1, sampler2, \n",
    "                    radius=0.1, coordinate_weight=2, ransac_threshold=0.01)\n",
    "print(\"runtime for num_samples=%s: %f\" % (num_samples,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(img_fname1,0)\n",
    "img2 = cv2.imread(img_fname2,0)\n",
    "cmap = plt.cm.get_cmap(\"hsv\", len(matches))\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img1, cmap='gray')\n",
    "axs[1].imshow(img2, cmap='gray')\n",
    "axs[0].plot(pointlist1[:,0], pointlist1[:,1],'w+',ms=15)\n",
    "axs[1].plot(pointlist2[:,0], pointlist2[:,1],'w+',ms=15)\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')\n",
    "for i,candidate in enumerate(matches): \n",
    "    axs[0].plot(candidate[0,0], candidate[0,1], c=cmap(i), marker='o')\n",
    "    axs[1].plot(candidate[1,0], candidate[1,1], c=cmap(i), marker='o')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Match real vessel detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load detected (& preregistered) landmarks, ROI coordinates and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS ###\n",
    "brainid = \"B20\"\n",
    "structure = \"V1_l\"\n",
    "fixed = 1529\n",
    "moving = 1530\n",
    "numLandmarks = 100   # use only best x landmarks for constellation matching\n",
    "use_preregistration = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read detected landmarks in fixed and moving image\n",
    "l_fixed = h5py.File(\"../data/{}_{}_{}_vessels.h5\".format(brainid,structure,fixed))[\"data\"][:numLandmarks,:2]\n",
    "l_moving = h5py.File(\"../data/{}_{}_{}_vessels.h5\".format(brainid,structure,moving))[\"data\"][:numLandmarks,:2]\n",
    "print(l_fixed.shape[0], l_moving.shape[0])\n",
    "if use_preregistration:\n",
    "    # transform moving landmarks with preregistration\\n\",\t\n",
    "    prereg_file = \"../data/{}_{}_transformation.json\".format(brainid,moving)\n",
    "    prereg = transformation.Transformation.from_json(prereg_file)\n",
    "    prereg_inverse = transformation.Transformation.from_json(prereg_file, inverse=True)\n",
    "    l_moving = prereg.apply_to_coords(l_moving, 0.001, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constellation Matching\n",
    "\n",
    "### Parameters for constellation matching:\n",
    "* **num_samples**: Number of hashes added to KDTree for fixed and moving landmarks (depends on #landmarks -> more samples needed for increasing number of landmarks)\n",
    "* **lambda**: Weight for absolute landmark coordinates in hash code (should be >1; 2 works good)\n",
    "* **ransac**: Hessian threshold for homography ransac on matched normalized landmark coordinates (0.01 works good)\n",
    "* **radius**: Radius for finding similar hashes in KDTree, could be calculated in match()-function with $$radius = \\sqrt{(\\lambda*maxDist*scale)^2*3 + \\Delta relativ\\_quad\\_positions^2 * 4}$$, where $scale$ = scale used in normalization of landmarks (known in match() function), $maxDist$ = maximal distance between corresponding pixels in fixed and moving image (after preregistration, ~250), $\\Delta relativ\\_quad\\_positions$ = maximal allowed distance between cx, cy, dx and dy of similar quads (0.0015 seems to be a good value here). Is it necessary to adapt radius in relation to the ratio of #landmarks/num_samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constellation matching\n",
    "num_samples = 50000\n",
    "sampler1 = clm.RandomSampler(len(l_fixed), 4, num_samples)\n",
    "sampler2 = clm.RandomSampler(len(l_moving), 4, num_samples)\n",
    "start = time.time()\n",
    "matches = clm.match(l_fixed, l_moving, sampler1, sampler2, \n",
    "                    radius=0.025, coordinate_weight=2, ransac_threshold=0.01) \n",
    "print(\"runtime for num_samples=%s: %f\" % (num_samples,time.time()-start))\n",
    "if use_preregistration and len(matches) > 0:\n",
    "    # transform moving match coordinates back to original moving image space:\n",
    "    matches_moving = prereg_inverse.apply_to_coords(matches[:,1], 0.001, 0.001)\n",
    "    matches = np.hstack((matches[:,0], matches_moving)).reshape(-1,2,2)\n",
    "print(\"Found %d matches\"%len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and ROIs for plotting\n",
    "scale = 0.1\n",
    "roifile = h5py.File(\"../data/{}_{}_rois.h5\".format(brainid,structure))\n",
    "roi_fixed = roifile[\"{}/roi\".format(fixed)][:]\n",
    "roi_moving = roifile[\"{}/roi\".format(moving)][:]\n",
    "roifile.close()\n",
    "img_fixed = cv2.imread(\"../data/{}_{}_{}_scale0.1.tif\".format(brainid,structure,fixed),0)\n",
    "img_moving = cv2.imread(\"../data/{}_{}_{}_scale0.1.tif\".format(brainid,structure,moving),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot landmarks and matches\n",
    "if use_preregistration:\n",
    "    l_moving_orig = prereg_inverse.apply_to_coords(l_moving, 0.001, 0.001)\n",
    "else:\n",
    "    l_moving_orig = l_moving\n",
    "cmap = plt.cm.get_cmap(\"hsv\", len(matches))\n",
    "fig,axs = plt.subplots(2,1)\n",
    "axs[0].imshow(img_fixed, cmap='gray')\n",
    "axs[1].imshow(img_moving, cmap='gray')\n",
    "# plot (landmarks - roi-offset) * scale according to downscaled images (0.1)\n",
    "axs[0].plot((l_fixed[:,0]-roi_fixed[0,0])*scale, (l_fixed[:,1]-roi_fixed[0,1])*scale,'w+',ms=10)\n",
    "axs[1].plot((l_moving_orig[:,0]-roi_moving[0,0])*scale, (l_moving_orig[:,1]-roi_moving[0,1])*scale,'w+',ms=10)\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')\n",
    "for i,match in enumerate(matches): \n",
    "    # plot matched coordinates - roi-offset * scale according to downscaled images (0.1)\n",
    "    axs[0].plot((match[0,0]-roi_fixed[0,0])*scale, (match[0,1]-roi_fixed[0,1])*scale, c=cmap(i), marker='o')\n",
    "    axs[1].plot((match[1,0]-roi_moving[0,0])*scale, (match[1,1]-roi_moving[0,1])*scale, c=cmap(i), marker='o')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbor Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "import math\n",
    "def homography_ransac(matches, residual_threshold=155):\n",
    "    print(\"mts vor RANSAC: {}\".format(matches.shape))\n",
    "    landmarks1, landmarks2 = matches[:,0], matches[:,1]\n",
    "    findingPosSampleProbability = 0.999\n",
    "    percentageOutliers = 0.997\n",
    "    numIterations = int(math.ceil(math.log(1-findingPosSampleProbability)/math.log(1-(1-percentageOutliers))))\n",
    "    model_robust, inliers = ransac((landmarks1, landmarks2), AffineTransform,\n",
    "                                   min_samples=3, residual_threshold=residual_threshold, max_trials=numIterations)\n",
    "    if inliers is None:\n",
    "        print(\"Ransac found no inliers.\")\n",
    "        inliers = list(range(len(matches)))\n",
    "    result = matches[inliers]\n",
    "    print(\"mts nach RANSAC: {}\".format(result.shape))\n",
    "    return result\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "def knn_matching(l_fixed, l_moving, k=3):\n",
    "    matches = []\n",
    "    tree_fixed = KDTree(l_fixed[:,:2], leaf_size=2, metric='minkowski')\n",
    "    for l in l_moving:\n",
    "        match_indices = tree_fixed.query([l], k=k, return_distance=False)[0]\n",
    "        for m in match_indices:\n",
    "            matches.append([l_fixed[m],l])\n",
    "    tree_moving = KDTree(l_moving[:,:2], leaf_size=2, metric='minkowski')\n",
    "    for l in l_fixed:\n",
    "        match_indices = tree_moving.query([l], k=k, return_distance=False)[0]\n",
    "        for m in match_indices:\n",
    "            matches.append([l, l_moving[m]])\n",
    "    if len(matches) > 0:\n",
    "        matches = np.unique(np.array(matches), axis=0)\n",
    "    matches = homography_ransac(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "matches_knn = knn_matching(l_fixed, l_moving, k=2)\n",
    "if use_preregistration and len(matches) > 0:\n",
    "    # transform moving match coordinates back to original moving image space:\n",
    "    matches_knn_moving = prereg_inverse.apply_to_coords(matches_knn[:,1], 0.001, 0.001)\n",
    "    matches_knn = np.hstack((matches_knn[:,0], matches_knn_moving)).reshape(-1,2,2)\n",
    "print(\"Found {} matches.\".format(len(matches_knn)))\n",
    "print(\"Runtime:\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot landmarks and matches\n",
    "if use_preregistration:\n",
    "    l_moving_orig = prereg_inverse.apply_to_coords(l_moving, 0.001, 0.001)\n",
    "else:\n",
    "    l_moving_orig = l_moving\n",
    "cmap = plt.cm.get_cmap(\"hsv\", len(matches))\n",
    "fig,axs = plt.subplots(2,1)\n",
    "axs[0].imshow(img_fixed, cmap='gray')\n",
    "axs[1].imshow(img_moving, cmap='gray')\n",
    "# plot (landmarks - roi-offset) * scale according to downscaled images (0.1)\n",
    "axs[0].plot((l_fixed[:,0]-roi_fixed[0,0])*scale, (l_fixed[:,1]-roi_fixed[0,1])*scale,'w+',ms=10)\n",
    "axs[1].plot((l_moving_orig[:,0]-roi_moving[0,0])*scale, (l_moving_orig[:,1]-roi_moving[0,1])*scale,'w+',ms=10)\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')\n",
    "for i,match in enumerate(matches_knn): \n",
    "    # plot matched coordinates - roi-offset * scale according to downscaled images (0.1)\n",
    "    axs[0].plot((match[0,0]-roi_fixed[0,0])*scale, (match[0,1]-roi_fixed[0,1])*scale, c=cmap(i), marker='o')\n",
    "    axs[1].plot((match[1,0]-roi_moving[0,0])*scale, (match[1,1]-roi_moving[0,1])*scale, c=cmap(i), marker='o')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainmap.structures.matchers import drawing\n",
    "def evaluate_matches(landmarks, matches, filenames, outfilename, factor=2): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        landmarks (array-like): 2x[N/M]x2 list, containing detected LOCAL landmarks (x,y) of \n",
    "                        filenames[0] and filenames[1] in original spacing.\n",
    "        matches (dict): List of matched landmark coordinates per matching method (key), \n",
    "                        must also contain key \"manually\" with manually clicked ground truth matches.\n",
    "        filenames (array-like): List of the two ROI image filenames\n",
    "        outfilename (str): Format output filename, will be filled with matching-method-name+\"_transformed_evaluated\"\n",
    "    \"\"\"\n",
    "    # ground truth (slice1 is moving, slice0 fixed)\n",
    "    gt_affine = transformation.get_affine_transformation(matches[\"manually\"][1],matches[\"manually\"][0]) \n",
    "    t = transformation.Transformation(filenames[0],filenames[1],\"affine\",\"pixel\",gt_affine[:2],spacing=0.001)\n",
    "    x1_truth = t.apply_to_coords(matches[\"manually\"][1], 0.001, 0.001)\n",
    "    dists = [np.sqrt(np.sum((matches[\"manually\"][0][i] - x1_truth[i])**2)) for i in range(len(x1_truth))] \n",
    "    mu = np.mean(dists)\n",
    "    sigma = np.std(dists)\n",
    "    print(\"mean and std deviation of manual matches under ground truth transformation: {} {}\".format(mu,sigma))\n",
    "    \n",
    "    # get number of possible correct matches\n",
    "    landmarks1_transformed = t.apply_to_coords(landmarks[1], 0.001, 0.001)\n",
    "    pm = 0\n",
    "    for l0 in landmarks[0]: \n",
    "        pm += sum([1 for l1 in landmarks1_transformed if np.sqrt(np.sum((l0 - l1)**2))-mu<=factor*sigma])\n",
    "    print(\"possible correct matches: {}\".format(pm))\n",
    "\n",
    "    # get number of (in)correct matches per method\n",
    "    correct = {} # save lists of indices of correct matches\n",
    "    print\n",
    "    print(\"%-25s %15s %10s / %-15s %10s %10s\" %(\"method\",\"mean distance\",\"correct\",\n",
    "                                                \"found matches\", \"recall\", \"precision\"))\n",
    "    for key, value in matches.items():\n",
    "        if key == \"manually\": \n",
    "            continue\n",
    "        x0 = value[:,0]\n",
    "        x1 = t.apply_to_coords(value[:,1], 0.001, 0.001)\n",
    "        dists = [np.sqrt(np.sum((x0[i] - x1[i])**2)) for i in range(len(x0))] \n",
    "        corr = []\n",
    "        for i,e in enumerate(dists): \n",
    "            if abs(e-mu) <= factor*sigma: corr.append(i)\n",
    "        correct[key] = corr\n",
    "        recall = len(corr)/float(pm) \n",
    "        precision = len(corr)/float(len(value))\n",
    "        print(\"%-25s %15.2f %10d / %-15d %10.2f %10.2f\"%(key, np.mean(dists), len(corr), len(value), \n",
    "                                                         recall, precision))\n",
    "        # assuming that images have spacing of 0.01 mm and match coordinates 0.001 mm\n",
    "        drawing.draw_matches(None, value[:,0]*0.1, value[:,1]*0.1, filenames[0], filenames[1], \n",
    "                             outfilename.format(key+\"_transformed_evaluated\"), bbox0=None, bbox1=None, \n",
    "                             thickness=15, transformation=t, orig_spacing=0.01, correct_indices=corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add manually clicked matches (and convert into local coordinates): \n",
    "# save local, not preregistered match coordinates in original spacing in all_matches:\n",
    "all_matches = {}\n",
    "f = h5py.File(\"../data/{}-{}_manually_scale0.1.h5\".format(fixed, moving))\n",
    "all_matches[\"manually\"] = np.array([f[\"/matches/others\"][:,:2],       \n",
    "                                    f[\"/matches/others\"][:,2:4]])/scale\n",
    "all_matches[\"knn\"] = np.hstack((matches_knn[:,0] - roi_fixed[0], \n",
    "                                matches_knn[:,1] - roi_moving[0])).reshape(-1,2,2)\n",
    "all_matches[\"constellation\"] = np.hstack((matches[:,0] - roi_fixed[0], \n",
    "                                          matches[:,1] - roi_moving[0])).reshape(-1,2,2)\n",
    "\n",
    "# run evalutation\n",
    "evaluate_matches([l_fixed-roi_fixed[0], l_moving_orig-roi_moving[0]], all_matches, \n",
    "                 [\"../data/{}_{}_{}_scale0.1.tif\".format(brainid,structure,fixed), \n",
    "                  \"../data/{}_{}_{}_scale0.1.tif\".format(brainid,structure,moving)], \n",
    "                 \"../data/%s_%s_{}.tif\"%(brainid, structure), factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
