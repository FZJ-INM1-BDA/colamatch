{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colamatch as clm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from brainmap.transformation import transformation\n",
    "%matplotlib notebook\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(name)s [%(levelname)s]:%(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filenames and read images and landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fixed = 1\n",
    "s_moving = 2\n",
    "fixed_file = \"../data/section_%s.tif\"%(str(s_fixed).zfill(4))\n",
    "moving_file = \"../data/section_%s.tif\"%(str(s_moving).zfill(4)) \n",
    "fixed_landmarks = \"../data/section_%s.landmarks.txt\"%(str(s_fixed).zfill(4))\n",
    "moving_landmarks = \"../data/section_%s.landmarks.txt\"%(str(s_moving).zfill(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read landmarks and images\n",
    "l_fixed = np.loadtxt(fixed_landmarks).astype('int')\n",
    "l_moving = np.loadtxt(moving_landmarks).astype('int')\n",
    "img_fixed = cv2.imread(fixed_file,0)\n",
    "img_moving = cv2.imread(moving_file,0)\n",
    "print(len(l_fixed), len(l_moving))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform constellation matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "sampler_fixed = clm.RandomSampler(len(l_fixed), 4, num_samples)\n",
    "sampler_moving = clm.RandomSampler(len(l_moving), 4, num_samples)\n",
    "start = time.time()\n",
    "matches = clm.match(l_fixed, l_moving, sampler_fixed, sampler_moving, radius=0.1, lamda=2, ransac=0.01)\n",
    "print(\"runtime for num_samples=%s: %f\" % (num_samples,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap(\"hsv\", len(matches))\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img_fixed, cmap='gray')\n",
    "axs[1].imshow(img_moving, cmap='gray')\n",
    "axs[0].plot(l_fixed[:,0], l_fixed[:,1],'w+',ms=15)\n",
    "axs[1].plot(l_moving[:,0], l_moving[:,1],'w+',ms=15)\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')\n",
    "for i,candidate in enumerate(matches): \n",
    "    axs[0].plot(candidate[0,0], candidate[0,1], c=cmap(i), marker='o')\n",
    "    axs[1].plot(candidate[1,0], candidate[1,1], c=cmap(i), marker='o')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Match real vessel detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load detected (& preregistrered) landmarks, ROI coordinates and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS ###\n",
    "brainid = \"B20\"\n",
    "structure = \"V1_l\"\n",
    "fixed = 1529\n",
    "moving = 1530\n",
    "numLandmarks = 100   # use only best x landmarks for constellation matching\n",
    "use_preregistration = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read detected landmarks in fixed and moving image\n",
    "l_fixed = h5py.File(\"../data/{}_{}_{}_vessels.h5\".format(brainid,structure,fixed))[\"data\"][:numLandmarks,:2]\n",
    "l_moving = h5py.File(\"../data/{}_{}_{}_vessels.h5\".format(brainid,structure,moving))[\"data\"][:numLandmarks,:2]\n",
    "print(l_fixed.shape[0], l_moving.shape[0])\n",
    "if use_preregistration:\n",
    "    # transform moving landmarks with preregistration\n",
    "    prereg_file = \"../data/{}_{}_transformation.json\".format(brainid,moving)\n",
    "    prereg = transformation.Transformation.from_json(prereg_file)\n",
    "    prereg_inverse = transformation.Transformation.from_json(prereg_file, inverse=True)\n",
    "    l_moving = prereg.apply_to_coords(l_moving, 0.001, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and ROIs for plotting\n",
    "scale = 0.1\n",
    "roifile = h5py.File(\"../data/{}_{}_rois.h5\".format(brainid,structure))\n",
    "roi_fixed = roifile[\"{}/roi\".format(fixed)][:]\n",
    "roi_moving = roifile[\"{}/roi\".format(moving)][:]\n",
    "roifile.close()\n",
    "img_fixed = cv2.imread(\"../data/{}_{}_{}_scale0.1.tif\".format(brainid,structure,fixed),0)\n",
    "img_moving = cv2.imread(\"../data/{}_{}_{}_scale0.1.tif\".format(brainid,structure,moving),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constellation Matching\n",
    "\n",
    "### Parameters for constellation matching:\n",
    "* **num_samples**: Number of hashes added to KDTree for fixed and moving landmarks (depends on #landmarks -> more samples needed for increasing number of landmarks)\n",
    "* **lambda**: Weight for absolute landmark coordinates in hash code (should be >1; 2 works good)\n",
    "* **ransac**: Hessian threshold for homography ransac on matched normalized landmark coordinates (0.01 works good)\n",
    "* **radius**: Radius for finding similar hashes in KDTree, could be calculated in match()-function with\n",
    "$$radius = \\sqrt{(\\lambda*maxDist*scale)^2*3 + \\Delta relativ\\_quad\\_positions^2 * 4}$$, \n",
    "where $scale$ = scale used in normalization of landmarks (known in match() function), $maxDist$ = maximal distance between corresponding pixels in fixed and moving image (after preregistration, ~250), $\\Delta relativ\\_quad\\_positions$ = maximal allowed distance between cx, cy, dx and dy of similar quads (0.0015 seems to be a good value here). Is it necessary to adapt radius in relation to the ratio of #landmarks/num_samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constellation matching\n",
    "num_samples = 50000\n",
    "c2_fixed = clm.RandomSampler(len(l_fixed), 4, num_samples)\n",
    "c2_moving = clm.RandomSampler(len(l_moving), 4, num_samples)\n",
    "start = time.time()\n",
    "matches = clm.match(l_fixed, l_moving, c2_fixed, c2_moving, radius=0.025, lamda=2, ransac=0.01) \n",
    "print(\"runtime for num_samples=%s: %f\" % (num_samples,time.time()-start))\n",
    "if use_preregistration and len(matches) > 0:\n",
    "    # transform moving match coordinates back to original moving image space: \n",
    "    matches_moving = prereg_inverse.apply_to_coords(matches[:,1], 0.001, 0.001)\n",
    "    matches = np.hstack((matches[:,0], matches_moving)).reshape(-1,2,2)\n",
    "print(\"Found %d matches\"%len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot landmarks and matches\n",
    "if use_preregistration:\n",
    "    l_moving_orig = prereg_inverse.apply_to_coords(l_moving, 0.001, 0.001)\n",
    "else: \n",
    "    l_moving_orig = l_moving\n",
    "cmap = plt.cm.get_cmap(\"hsv\", len(matches))\n",
    "fig,axs = plt.subplots(2,1)\n",
    "axs[0].imshow(img_fixed, cmap='gray')\n",
    "axs[1].imshow(img_moving, cmap='gray')\n",
    "# plot (landmarks - roi-offset) * scale according to downscaled images (0.1)\n",
    "axs[0].plot((l_fixed[:,0]-roi_fixed[0,0])*scale, (l_fixed[:,1]-roi_fixed[0,1])*scale,'w+',ms=10)\n",
    "axs[1].plot((l_moving_orig[:,0]-roi_moving[0,0])*scale, (l_moving_orig[:,1]-roi_moving[0,1])*scale,'w+',ms=10)\n",
    "axs[0].axis('off')\n",
    "axs[1].axis('off')\n",
    "for i,match in enumerate(matches): \n",
    "    # plot matched coordinates - roi-offset * scale according to downscaled images (0.1)\n",
    "    axs[0].plot((match[0,0]-roi_fixed[0,0])*scale, (match[0,1]-roi_fixed[0,1])*scale, c=cmap(i), marker='o')\n",
    "    axs[1].plot((match[1,0]-roi_moving[0,0])*scale, (match[1,1]-roi_moving[0,1])*scale, c=cmap(i), marker='o')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
